{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "be09fcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\programdata\\anaconda3\\lib\\site-packages (3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -loudpickle (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -loudpickle (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\programdata\\anaconda3\\lib\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\cseka\\appdata\\roaming\\python\\python36\\site-packages (from opencv-python) (1.19.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -loudpickle (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -loudpickle (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    " !pip install wget\n",
    " !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c5e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb0bd15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "import sys\n",
    "import requests\n",
    "import zipfile\n",
    "import wget\n",
    "cwd = os.getcwd()\n",
    "train_dir='inaturalist_12K/train/' \n",
    "test_dir='inaturalist_12K/val/'\n",
    "savePath=cwd+'/DataSet/'\n",
    "classes=['Amphibia','Animalia','Arachnida','Aves','Fungi','Insecta','Mammalia','Mollusca','Plantae','Reptilia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e81fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_exists = exists(cwd+'/DataSet/nature_12K.zip')\n",
    "if(file_exists==False):\n",
    "    url='https://storage.googleapis.com/wandb_datasets/nature_12K.zip'\n",
    "    print('Downloading..')\n",
    "    wget.download(url,savePath)\n",
    "    \n",
    "extract_exists = exists(cwd+'/DataSet/inaturalist_12K')   \n",
    "if(extract_exists==False):   \n",
    "    savePath=cwd+'\\\\DataSet'\n",
    "    savefile=cwd+'\\\\DataSet\\\\nature_12K.zip'\n",
    "    print('Extracting..')\n",
    "    with zipfile.ZipFile(savefile, 'r') as zip_ref:\n",
    "        zip_ref.extractall(savePath)\n",
    "    print('Finished..')\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90f1e75",
   "metadata": {},
   "source": [
    "### Download and Extract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fb0095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir='inaturalist_12K/train/'\n",
    "test_dir='inaturalist_12K/val/'\n",
    "classes=['Amphibia','Animalia','Arachnida','Aves','Fungi','Insecta','Mammalia','Mollusca','Plantae','Reptilia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d34fa7c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random \n",
    "import cv2\n",
    "imagePath=os.getcwd()+'\\\\DataSet\\\\inaturalist_12K\\\\train'\n",
    "listImages=[]\n",
    "columns = 5\n",
    "rows = 5\n",
    "imcount=1\n",
    "\n",
    "for i in classes:\n",
    "    p=imagePath+'\\\\'+i\n",
    "    files=os.listdir( p)\n",
    "    img=random.choice(files)\n",
    "    imgplt=mpimg.imread( p+'\\\\'+str(img))\n",
    "    imgplt=cv2.resize(imgplt,(128,128)) \n",
    "    listImages.append(imgplt)\n",
    "    #plt.imshow(imgplt)\n",
    "    #fig.add_subplot(rows, columns, imcount)\n",
    "    #imcount+=1\n",
    "    #plt.axis('off')\n",
    "    #plt.title(i) \n",
    "\n",
    "_, axs = plt.subplots(1, 10, figsize=(15, 15))\n",
    "axs = axs.flatten()\n",
    "for img, ax,cls in zip(listImages, axs,classes):\n",
    "  \n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(str(cls))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f36404fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation , BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D , MaxPool2D,MaxPooling3D , Flatten , Dropout, Dense, Activation, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1dcca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dataset(seed):\n",
    "    cwd=os.getcwd()\n",
    "    imagesize=(64,64)\n",
    "    batchsize=32\n",
    "    train_dir = cwd+'\\\\DataSet\\\\inaturalist_12K\\\\train\\\\'\n",
    "    test_dir = cwd+'\\\\DataSet\\\\inaturalist_12K\\\\val\\\\'\n",
    "    print('Training Dataset')\n",
    "    def scale(image, label):\n",
    "        return tf.image.convert_image_dtype(image*(1.0/255), tf.float32), label\n",
    "\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        train_dir,\n",
    "         label_mode ='categorical',\n",
    "        validation_split=0.1,\n",
    "        subset=\"training\",\n",
    "        color_mode='rgb',\n",
    "        seed=seed,\n",
    "        image_size=imagesize,\n",
    "        batch_size=batchsize\n",
    "    )\n",
    "    #train_ds=train_ds.map(scale)\n",
    "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        train_dir,\n",
    "        validation_split=0.1,\n",
    "        subset=\"validation\",\n",
    "        seed=seed,\n",
    "        color_mode=\"rgb\",\n",
    "        label_mode ='categorical',\n",
    "        image_size=imagesize,\n",
    "        batch_size=batchsize,\n",
    "    )\n",
    "    #val_ds=val_ds.map(scale)\n",
    "    print('')\n",
    "    print('Test Dataset')\n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(test_dir,batch_size=batchsize, shuffle=True,image_size=imagesize,label_mode='categorical',\n",
    "        color_mode='rgb')\n",
    "    #test_ds=test_ds.map(scale)\n",
    "    return train_ds,val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d23b9377",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def Import_dataset(seed,augment_data=False):\n",
    "    cwd=os.getcwd()\n",
    "    imagesize=(128,128)\n",
    "    batchsize=32\n",
    "    image_size=128\n",
    "    train_dir = cwd+'\\\\DataSet\\\\inaturalist_12K\\\\train\\\\'\n",
    "    test_dir = cwd+'\\\\DataSet\\\\inaturalist_12K\\\\val\\\\'\n",
    "    print('Training Dataset')\n",
    "    if augment_data:\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                      rotation_range=90,\n",
    "                                      zoom_range=0.2,\n",
    "                                      shear_range=0.2,\n",
    "                                      validation_split=0.1,\n",
    "                                      horizontal_flip=True)\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255,validation_split=0.1)\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_ds = train_datagen.flow_from_directory(train_dir,subset=\"training\", color_mode='rgb',target_size=(image_size, image_size), batch_size=batchsize)\n",
    "    val_ds = train_datagen.flow_from_directory(train_dir,subset=\"validation\", color_mode='rgb',target_size=(image_size, image_size), batch_size=batchsize)\n",
    "    print('')\n",
    "    print('Test Dataset')\n",
    "    test_ds = test_datagen.flow_from_directory(test_dir, target_size=(128, 128),color_mode='rgb',batch_size=30)\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "    return train_ds,val_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e03c498",
   "metadata": {},
   "source": [
    "### Model consisting of 5 convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d841ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(filters, size_of_filters,\\\n",
    "        activation_function,\\\n",
    "        number_of_neurons_in_the_dense_layer,\\\n",
    "        number_of_classes,\\\n",
    "        dropout,\\\n",
    "        BatchNormalization=True):\n",
    "    model = Sequential()\n",
    "    num_of_filters=len(filters)\n",
    "    model.add(Conv2D(no_of_filters[0], size_of_filters[0],input_shape=(128,128,3),kernel_initializer=tf.keras.initializers.GlorotNormal(seed=42),activation=activation_function[0]))     \n",
    "    for i in range(num_of_filters-1):\n",
    "        model.add(Conv2D(no_of_filters[i+1], size_of_filters[i+1],kernel_initializer=tf.keras.initializers.GlorotNormal(seed=42)))\n",
    "        if BatchNormalization:\n",
    "            model.add(tf.keras.layers.BatchNormalization(momentum= 0.99))\n",
    "        model.add(Activation(activation_function[i]))\n",
    "        model.add(MaxPooling2D((2,2)))\n",
    "        model.add(Dropout(dropout))\n",
    "       \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(number_of_neurons_in_the_dense_layer,activation=activation_function[-2])) \n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(number_of_classes, activation=activation_function[-1]))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56ebbc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset\n",
      "Found 9000 images belonging to 10 classes.\n",
      "Found 999 images belonging to 10 classes.\n",
      "\n",
      "Test Dataset\n",
      "Found 2000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds,val_ds,test_ds=Import_dataset(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64c21138",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_filters = [64,64,64,64,64]\n",
    "size_of_filters = [(3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]\n",
    "activation_function = ['relu','relu','relu','relu','relu','relu','softmax']\n",
    "number_of_neurons_in_the_dense_layer = 256\n",
    "dropout=0.3\n",
    "number_of_classes=10\n",
    "model=CNN(no_of_filters,size_of_filters,activation_function,number_of_neurons_in_the_dense_layer,number_of_classes,dropout) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "47c03f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "282/282 [==============================] - 731s 3s/step - loss: 2.3628 - accuracy: 0.1600 - val_loss: 2.4389 - val_accuracy: 0.1051\n",
      "Epoch 2/4\n",
      "282/282 [==============================] - 705s 2s/step - loss: 2.1448 - accuracy: 0.2119 - val_loss: 2.1709 - val_accuracy: 0.2112\n",
      "Epoch 3/4\n",
      "282/282 [==============================] - 679s 2s/step - loss: 2.1109 - accuracy: 0.2378 - val_loss: 2.1896 - val_accuracy: 0.2142\n",
      "Epoch 4/4\n",
      "282/282 [==============================] - 646s 2s/step - loss: 2.0489 - accuracy: 0.2630 - val_loss: 2.1961 - val_accuracy: 0.2262\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=[tf.keras.losses.CategoricalCrossentropy()], metrics=['accuracy'])\n",
    "hist=model.fit(train_ds, epochs=4,validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b2fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(cwd+'\\\\models\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf83c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model(cwd+'\\\\models\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e80b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "prediction=model.predict(test_ds)\n",
    "predictionz=np.argmax(prediction,axis=1)\n",
    "accuracy_score(test_ds.labels,predictionz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64996972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
